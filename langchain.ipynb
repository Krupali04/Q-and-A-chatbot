{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPEN_API_KEY\"]=\"sk-proj-tB9jMbXCGScSovHLnCPPgXwcAAn7TVvh7ETA-zGq3_Wh7lRGbDu_aColSxARGxQOxEH6_Ho3rWXarkA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vc/4b9h10p51h99m8_w7_zyttk80000gn/T/ipykernel_81166/503934342.py:1: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm=OpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],temperature=0.6)\n"
     ]
    }
   ],
   "source": [
    "llm=OpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"],temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vc/4b9h10p51h99m8_w7_zyttk80000gn/T/ipykernel_81166/445092861.py:2: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(llm.predict(text))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?\n",
      "\n",
      "As of September 2021, the latest iPhone model is the iPhone 13.\n"
     ]
    }
   ],
   "source": [
    "text=\"Which is the latest Iphone model\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=\"hf_eojKbpassssHleGCSaDcfvQuhdiQj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vc/4b9h10p51h99m8_w7_zyttk80000gn/T/ipykernel_81166/3975980350.py:2: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  llm_huggingface=HuggingFaceHub(huggingfacehub_api_token=os.environ['HUGGINGFACEHUB_API_TOKEN'],\n",
      "/Users/krupalitejani/Desktop/LLM/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "llm_huggingface=HuggingFaceHub(huggingfacehub_api_token=os.environ['HUGGINGFACEHUB_API_TOKEN'],\n",
    "                               repo_id='deepseek-ai/DeepSeek-R1',\n",
    "                               model_kwargs={'temperature':0.6,'max_length':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krupalitejani/Desktop/LLM/venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'what is capital of India?\\n\\nDelhi is the capital of India. It is the largest commercial city of northern India, and also the largest city in the country by area. It is situated on the banks of the Yamuna River, and is divided into two parts - Old Delhi and New Delhi. Delhi is known for its rich history, cultural heritage, and diverse cuisine. It is also a major hub for politics, business, culture, and tourism in India.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=llm_huggingface.predict('what is capital of India')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe capital of India is New Delhi.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=llm.predict('what is capital of India')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/krupalitejani/Desktop/LLM/venv/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a joke about AI.\n",
      "I've got a joke for you, but I'm not sure if I should tell it. I don't want to botch it up.\n"
     ]
    }
   ],
   "source": [
    "print(llm_huggingface.predict(\"Tell me a joke about AI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Why did the robot go on a diet?\n",
      "\n",
      "Because it wanted to reduce its \"byte\" size!\n"
     ]
    }
   ],
   "source": [
    "print(llm.predict(\"Tell me a joke about AI\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROMPT TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "temp_food=PromptTemplate(input_variables=['Food'],\n",
    "               template='Tell me if {Food} is veg or non-veg')\n",
    "\n",
    "temp_type=PromptTemplate(input_variables=['foodtype'],\n",
    "                    template='Give me some famous {foodtype} dishes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vc/4b9h10p51h99m8_w7_zyttk80000gn/T/ipykernel_81166/3025744683.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain_food=LLMChain(llm=llm,prompt=temp_food, output_key='foodtype')\n",
      "/var/folders/vc/4b9h10p51h99m8_w7_zyttk80000gn/T/ipykernel_81166/3025744683.py:4: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain_food.run('milk')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. Macaroni and cheese\\n2. Grilled cheese sandwich\\n3. Cheese fondue\\n4. Cheese pizza\\n5. Cheese souffle\\n6. French onion soup with melted cheese on top\\n7. Cheeseburger\\n8. Lasagna\\n9. Cheese and charcuterie board\\n10. Cheese enchiladas\\n11. Cheese-stuffed ravioli\\n12. Cheese and vegetable quiche\\n13. Cheese-stuffed peppers\\n14. Cheese and ham croquettes\\n15. Cheese and tomato bruschetta\\n16. Cheese and mushroom risotto\\n17. Cheese and spinach stuffed shells\\n18. Cheese and broccoli casserole\\n19. Cheese and potato gratin\\n20. Cheese and bacon potato skins.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain_food=LLMChain(llm=llm,prompt=temp_food, output_key='foodtype')\n",
    "chain_food.run('milk')\n",
    "\n",
    "chain_type=LLMChain(llm=llm,prompt=temp_type,output_key='dishes')\n",
    "chain_type.run('cheese')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. California Roll\\n2. Spicy Tuna Roll\\n3. Dragon Roll\\n4. Rainbow Roll\\n5. Philadelphia Roll\\n6. Dynamite Roll\\n7. Spider Roll\\n8. Caterpillar Roll\\n9. Volcano Roll\\n10. Tempura Roll\\n11. Dragon Roll\\n12. Salmon Avocado Roll\\n13. Tuna Sashimi\\n14. Eel Nigiri\\n15. Shrimp Tempura Roll\\n16. Lobster Roll\\n17. Yellowtail Sashimi\\n18. Cucumber Roll\\n19. Salmon Roe Nigiri\\n20. Tuna Tataki Roll'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain=SimpleSequentialChain(chains=[chain_food,chain_type])\n",
    "chain.run('sushi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chains=SequentialChain(chains=[chain_food,chain_type], input_variables=['Food'],output_variables=['foodtype','dishes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vc/4b9h10p51h99m8_w7_zyttk80000gn/T/ipykernel_81166/1408500308.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chains({'Food':'chicken'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Food': 'chicken',\n",
       " 'foodtype': '\\n\\nChicken is considered non-veg as it comes from an animal.',\n",
       " 'dishes': ' that are popular around the world:\\n\\n1. Fried Chicken - a dish consisting of chicken pieces that have been coated in a seasoned batter and deep-fried.\\n\\n2. Chicken Curry - a dish made with chicken, spices, and a variety of vegetables, commonly found in Indian and Southeast Asian cuisines.\\n\\n3. Roast Chicken - a classic dish where a whole chicken is seasoned and roasted in the oven until the skin is crispy and the meat is tender.\\n\\n4. Chicken Parmigiana - a breaded chicken dish topped with tomato sauce and cheese, often served with pasta.\\n\\n5. Chicken Tikka Masala - a popular Indian dish made with marinated chicken pieces cooked in a creamy tomato-based sauce.\\n\\n6. Chicken Adobo - a Filipino dish made with chicken cooked in soy sauce, vinegar, and garlic.\\n\\n7. Chicken Shawarma - a Middle Eastern dish made with seasoned chicken cooked on a rotating spit and served in a wrap or pita bread.\\n\\n8. Chicken Katsu - a Japanese dish consisting of breaded and fried chicken cutlets served with a sweet and tangy sauce.\\n\\n9. Chicken Satay - a Southeast Asian dish consisting of marinated and grilled chicken skewers served with a peanut sauce.\\n\\n10. Coq au Vin - a French dish made with'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chains({'Food':'Chicken'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatmodels With ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage,SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vc/4b9h10p51h99m8_w7_zyttk80000gn/T/ipykernel_81166/713334619.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chatllm=ChatOpenAI(openai_api_key=os.environ['OPEN_API_KEY'],temperature=0.6,model='gpt-4')\n"
     ]
    }
   ],
   "source": [
    "chatllm=ChatOpenAI(openai_api_key=os.environ['OPEN_API_KEY'],temperature=0.6,model='gpt-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vc/4b9h10p51h99m8_w7_zyttk80000gn/T/ipykernel_81166/51257863.py:1: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chatllm([\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"1. Sushi in Japan: There's nothing like eating sushi in its birthplace. You can find the freshest sushi at Tokyo's Tsukiji Fish Market.\\n\\n2. Pizza in Naples, Italy: Naples is the birthplace of pizza. The classic Neapolitan pizza is a must-try, with its thin, soft and chewy crust.\\n\\n3. Street Food in Bangkok, Thailand: The streets of Bangkok are filled with food stalls serving up delicious Thai food like Pad Thai, Som Tum (green papaya salad), and Mango Sticky Rice.\\n\\n4. Tapas in Spain: Tapas are small dishes typically served with drinks at bars. They can range from simple snacks like olives and cheese to more substantial dishes like patatas bravas or gambas al ajillo.\\n\\n5. Seafood in Maine, USA: Maine is known for its fresh seafood, particularly its lobster. A lobster roll from Maine is an absolute must-try.\\n\\n6. Barbecue in Texas, USA: Texas is famous for its barbecue, especially its slow-cooked, smoked brisket.\\n\\n7. Poutine in Quebec, Canada: This Canadian dish is made of fries topped with cheese curds and drenched in gravy.\\n\\n8. Dim Sum in Hong Kong: Dim sum is a style of Chinese cuisine where food is served in small, bite-sized portions, typically in steamer baskets or on small plates.\\n\\n9. Wine Tasting in Bordeaux, France: Bordeaux is one of the most renowned wine regions in the world. A wine tasting tour here would be a great experience for any foodie.\\n\\n10. Chocolate Tour in Belgium: Belgium is famous for its high-quality chocolate. Many shops in cities like Brussels and Bruges offer chocolate tours and tastings.\\n\\nRemember, the best way to experience food is not only to eat it but to understand its history and the culture it comes from. Bon app√©tit!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 384, 'prompt_tokens': 22, 'total_tokens': 406, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-345b47c6-7c85-445f-89af-7b082d100ae4-0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm([\n",
    "SystemMessage(content='you are a foodie'),\n",
    "HumanMessage(content='suggest me some good food experiences')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template + LLM +Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Commaseperatedoutput(BaseOutputParser):\n",
    "    def parse(self,text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"Your are a helpful assistant. When the use given any input , you should generate 5 words synonyms in a comma seperated list\"\n",
    "human_template=\"{text}\"\n",
    "chatprompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",template),\n",
    "    (\"human\",human_template)\n",
    "\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=chatprompt|chatllm|Commaseperatedoutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meal', ' cuisine', ' nourishment', ' sustenance', ' grub']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\":\"food\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
